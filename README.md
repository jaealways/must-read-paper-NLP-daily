# must-read-paper-daily-NLP
List of papers with recent trends for NLP in 2024

## 2022
- [2022 NAACL](https://github.com/jaealways/must-read-paper-daily/blob/main/2022/NAACL.md)

## 2023
- [2023 ACL](https://github.com/jaealways/must-read-paper-daily/blob/main/2023/ACL.md)
- [2023 EACL](https://github.com/jaealways/must-read-paper-daily/blob/main/2023/EACL.md)
- [2023 EMNLP](https://github.com/jaealways/must-read-paper-daily/blob/main/2023/EMNLP.md)
- [2023 NeurIPS](https://github.com/jaealways/must-read-paper-daily/blob/main/2023/NeurIPS.md)
- [2023 WMT](https://github.com/jaealways/must-read-paper-daily/blob/main/2023/WMT.md)


## Updated on 2024.02.12

# Must-read LIST

|Date|Title|Authors|PDF|TAGS|TLDR|
|---|---|---|---|---|---|
|**02-20**|**When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories**|A Mallen et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|ACL'23, LLM, evaluation|**[KOR]()**|
|**02-19**|**Large Language Models Can Be Easily Distracted by Irrelevant Context**|F Shi et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|ICML'23, LLM, evaluation|**[KOR]()**|
|**02-18**|**The Parrot Dilemma: Human-Labeled vs. LLM-augmented Data in Classification Tasks**|AG Møller et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|ACL'23, LLM, evaluation|**[KOR]()**|
|**02-17**|**BAYESIAN OPTIMIZATION OF CATALYSTS WITH IN-CONTEXT LEARNING**|MC Ramos et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|preprint'23, LLM, evaluation|**[KOR]()**|
|**02-16**|**LARGE LANGUAGE MODELS AS OPTIMIZERS**|C Yang et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|preprint'23, Deepmind, LLM, evaluation|**[KOR]()**|
|**02-15**|**Chain-of-Thought Prompting Elicits Reasoning in Large Language Models**|J Wei et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|NeurIPS'22, LLM, evaluation|**[KOR]()**|
|**02-14**|**RLPROMP: Optimizing Discrete Text Prompts with Reinforcement Learning**|M Deng et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|EMNLP'22, LLM, evaluation|**[KOR]()**|
|**02-13**|**Iter-RetGen: Enhancing Retrieval augmented Large Language Models with Iterative Retrieval**|Z Shao et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|ACL'23, LLM, evaluation|**[KOR]()**|
|**02-12**|**InstructGPT: Training language models to follow instructions with human feedback**|L Ouyang et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|NeurIPS'22, OpenAI, LLM, evaluation|**[KOR]()**|
|**02-11**|**LIMA: Less Is More for Alignment**|C Zhou et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|preprint'23, MetaAI, LLM, evaluation|**[KOR]()**|
|**02-10**|**MCSE: Multimodal Contrastive Learning of Sentence Embeddings**|M Zhang et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|NAACL'22, LLM, evaluation|**[KOR]()**|
|**02-09**|**LLaMA: Open and Efficient Foundation Language Models**|H Touvron et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|preprint'23, MetaAI, LLM, evaluation|**[KOR]()**|
|**02-08**|**INSTRUCTION TUNING WITH GPT-4**|B Peng et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|preprint'23, LLM, evaluation|**[KOR]()**|
|**02-07**|**Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering**|S Siriwardhana et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|TACL'23, LLM, evaluation|**[KOR]()**|
|**02-06**|**Mistral 7B**|AQ Jiang et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|preprint'23, LLM, evaluation|**[KOR]()**|
|**02-05**|**The Internal State of an LLM Knows When its Lying**|A Azaria et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|EMNLP'23, LLM, evaluation|**[KOR]()**|
|**02-04**|**DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction**|M Pourreza et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|NeurIPS'23, LLM, evaluation|**[KOR]()**|
|**02-03**|**Revisiting the Gold Standard: Summarization Evaluation with Robust Human Evaluation**|Y Liu  et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|ACL'23, LLM, evaluation|**[KOR]()**|
|**02-02**|**PEER: A Collaborative Language Model**|T Schick et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|ICLR'23, LLM, evaluation|**[KOR]()**|
|**02-01**|**DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models**|YS Chuang  et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|ICLR'24, LLM, evaluation|**[KOR]()**|
|**01-31**|**Can Large Language Models Be an Alternative to Human Evaluation?**|CH Chiang et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|ACL'23, LLM, evaluation|**[KOR]()**|
|**01-30**|**When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories**|A Mallen et.al.|[2212.10511](https://arxiv.org/pdf/2212.10511.pdf)|ACL'23, LLM, QA|**[KOR]()**|
|**01-29**|**Align before Fuse: Vision and Language Representation Learning with Momentum Distillation**|SY Gadre et.al.|[2107.07651](https://arxiv.org/pdf/2107.07651.pdf)|NeurIPS'21, Distillation, Multi-modal|**[KOR]()**|
|**01-28**|**Making Large Language Models Better Reasoners with Step-Aware Verifier**|Y Li et.al.|[2206.02336](https://arxiv.org/pdf/2206.02336.pdf)|ACL'23, Reasoning|**[KOR]()**|
|**01-27**|**LONGEVAL: Guidelines for Human Evaluation of Faithfulness in Long-form Summarization**|K Krishna et.al.|[2301.13298](https://arxiv.org/pdf/2301.13298.pdf)|EACL'23, Summarization|**[KOR]()**|
|**01-26**|**SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization**|H Kim et.al.|[2212.10465](https://arxiv.org/pdf/2212.10465.pdf)|EMNLP'23, Distillation|**[KOR]()**|
|**01-25**|**OpenAssistant Conversations - Democratizing Large Language Model Alignment**|A Köpf et.al.|[2304.07327](https://arxiv.org/pdf/2304.07327.pdf)|NeurIPS'23, LLM|**[KOR]()**|
|**01-24**|**Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection**|Y Bai et.al.|[2306.04637](https://arxiv.org/pdf/2306.04637.pdf)|NeurIPS'23, In-Context Learning|**[KOR]()**|
|**01-23**|**DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings**|YS Chuang et.al.|[2204.10298](https://arxiv.org/pdf/2204.10298.pdf)|NAACL'22, Contrasive Learning|**[KOR]()**|
|**01-22**|**ProQA: Structural Prompt-based Pre-training for Unified Question Answering**|W Zhong et.al.|[2205.04040](https://arxiv.org/pdf/2205.04040.pdf)|NAACL'22, QA, prompt|**[KOR]()**|
|**01-21**|**DataComp: In search of the next generation of multimodal datasets**|SY Gadre et.al.|[2304.14108](https://arxiv.org/pdf/2304.14108.pdf)|ACL'23, benchmark|**[KOR]()**|
|**01-20**|**LeanDojo: Theorem Proving with Retrieval-Augmented Language Models**|K Yang et.al.|[2306.15626](https://arxiv.org/pdf/2306.15626.pdf)|NeurIPS'23, Retrieval-Augmented|**[KOR]()**|
|**01-19**|**NewsEdits: A Dataset of News Article Revision Histories and a Novel Document-Level Reasoning Challenge**|A Spangher et.al.|[2206.07106](https://arxiv.org/pdf/2206.07106.pdf)|NAACL'22, Dataset, Reasoning|**[KOR]()**|
|**01-18**|**What the DAAM: Interpreting Stable Diffusion Using Cross Attention**|R Tang et.al.|[2210.04885](https://arxiv.org/pdf/2210.04885.pdf)|ACL'23, multi-modal|**[KOR]()**|
|**01-17**|**Do Androids Laugh at Electric Sheep? Humor Understanding Benchmarks from The New Yorker Caption Contest**|J.Hessel et.al.|[2209.06293](https://arxiv.org/pdf/2209.06293.pdf)|ACL'23, benchmark|**[KOR]()**|
|**01-16**|**Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions**|M.Parmar et.al.|[2205.00415](https://arxiv.org/pdf/2205.00415.pdf)|EACL'23, annotation|**[KOR]()**|
|**01-15**|**DECODINGTRUST: A Comprehensive Assessment of Trustworthiness in GPT Models**|Yuqi Nie et.al.|[2306.11698](https://arxiv.org/pdf/2306.11698.pdf)|NeurIPS'23, evaluation| **[KOR]()**|
|**01-14**|**Do Prompt-Based Models Really Understand the Meaning of Their Prompts?**|Albert Webson et.al.|[2109.01247](https://arxiv.org/pdf/2109.01247.pdf)|NAACL'22, prompt| **[KOR]()**|
|**01-13**|**Template-free Prompt Tuning for Few-shot NER**|Ruotian Ma et.al.|[2109.13532](https://arxiv.org/pdf/2109.13532.pdf)|NAACL'22, prompt| **[KOR]()**|
|**01-12**|**Probing via Prompting and Pruning**|Jiaoda Li et.al.|[2207.01736](https://arxiv.org/pdf/2207.01736.pdf)|NAACL'22, prompt| **[KOR]()**|
|**01-11**|**Are Emergent Abilities of Large Language Models a Mirage?**|R.Schaeffer et.al.|[2304.15004](https://arxiv.org/pdf/2304.15004.pdf)|NeurIPS'23, LLM| **[KOR]()**|
|**01-10**|**Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters**|B.Wang et.al.|[2212.10001](https://arxiv.org/pdf/2212.10001.pdf)|ACL'23, prompt| **[KOR]()**|
|**01-09**|**A TIME SERIES IS WORTH 64 WORDS: LONG-TERM FORECASTING WITH TRANSFORMERS**|Yuqi Nie et.al.|[2211.14730](https://arxiv.org/pdf/2211.14730.pdf)|ICLR'23, time-series| **[KOR]()**|
|**01-08**|**Do PLMs Know and Understand Ontological Knowledge?**|Weiqi Wu et.al.|[2309.05936](https://arxiv.org/pdf/2309.05936.pdf)|ACL'23, PLM| **[KOR]()**|
|**01-07**|**QLoRA: Efficient Finetuning of Quantized LLMs**|Tim Dettmers et.al.|[2305.14314](https://arxiv.org/pdf/2305.14314.pdf)|NeurIPS'23, fine-tuning|**[KOR]()**| 
|**01-06**|**Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents**|Weiwei Sun et.al.|[2105.09680](https://arxiv.org/pdf/2105.09680.pdf)|EMNLP'23, LLM| **[KOR]()**|
|**01-05**|**Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models**|Myra Cheng et.al.|[2305.18189](https://arxiv.org/pdf/2305.18189.pdf)|ACL'23, prompt| **[KOR]()**|
|**01-04**|**From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models**|Shangbin Feng et.al.|[2305.08283](https://arxiv.org/pdf/2305.08283.pdf)|ACL'23, AI ethics| **[KOR](./TLDR/From Pretraining Data to Language Models to Downstream Tasks Tracking the Trails of Political Biases Leading to Unfair NLP Models.md)**|
|**01-03**|**Mamba: Linear-Time Sequence Modeling with Selective State Spaces**|Albert Gu et.al.|[2312.00752](https://arxiv.org/ftp/arxiv/papers/2312/2312.00752.pdf)|ICLR'24, LLM| **[KOR]()**|
|**01-02**|**FRUIT: Faithfully Reflecting Updated Information in Text**|Robert L. Logan IV et.al.|[2112.08634](https://arxiv.org/pdf/2112.08634.pdf)|NAACL'22, Information, dataset| **[KOR]()** |
|**01-01**|**Scaling Data-Constrained Language Models**|Niklas Muennighoff et.al.|[2305.16264](https://arxiv.org/pdf/2305.16264.pdf)|NeurIPS'23, LLM| **[KOR]()** |

