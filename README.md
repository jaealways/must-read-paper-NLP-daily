# must-read-paper-daily-NLP
List of papers with recent trends for NLP in 2024

## 2022
- [2022 NAACL](./2022/NAACL.md)

## 2023
- [2023 ACL](./2023/ACL.md)
- [2023 EACL](./2023/EACL.md)
- [2023 EMNLP](./2023/EMNLP.md)
- [2023 NeurIPS](./2023/NeurIPS.md)
- [2023 WMT](./2023/WMT.md)


## Updated on 2024.02.12

# Must-read LIST

|Date|Title|Authors|PDF|TAGS|TLDR|
|---|---|---|---|---|---|
|**02-20**|**Large language models are human-level prompt engineers**|Y Zhou et.al.|[2211.01910](https://arxiv.org/pdf/2211.01910.pdf)|ICLR'23|[KOR](./TLDR/Large-language-models-are-human-level-prompt-engineers.md)|
|**02-19**|**Large Language Models Can Be Easily Distracted by Irrelevant Context**|F Shi et.al.|[2302.00093](https://arxiv.org/pdf/2302.00093.pdf)|ICML'23|[KOR](./TLDR/Large-Language-Models-Can-Be-Easily-Distracted-by-Irrelevant-Context.md)|
|**02-18**|**The Parrot Dilemma: Human-Labeled vs. LLM-augmented Data in Classification Tasks**|AG Møller et.al.|[2304.13861](https://arxiv.org/pdf/2304.13861.pdf)|ACL'23|[KOR](./TLDR/The-Parrot-Dilemma-Human-Labeled-vs.-LLM-augmented-Data-in-Classification-Tasks.md)|
|**02-17**|**BAYESIAN OPTIMIZATION OF CATALYSTS WITH IN-CONTEXT LEARNING**|MC Ramos et.al.|[2304.05341](https://arxiv.org/pdf/2304.05341.pdf)|preprint'23|[KOR](./TLDR/BAYESIAN-OPTIMIZATION-OF-CATALYSTS-WITH-IN-CONTEXT-LEARNING.md)|
|**02-16**|**LARGE LANGUAGE MODELS AS OPTIMIZERS**|C Yang et.al.|[2309.03409](https://arxiv.org/pdf/2309.03409.pdf)|preprint'23, Deepmind|[KOR](./TLDR/LARGE-LANGUAGE-MODELS-AS-OPTIMIZERS.md)|
|**02-15**|**Chain-of-Thought Prompting Elicits Reasoning in Large Language Models**|J Wei et.al.|[2201.11903](https://arxiv.org/pdf/2201.11903.pdf)|NeurIPS'22|[KOR](./TLDR/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models.md)|
|**02-14**|**RLPROMPT: Optimizing Discrete Text Prompts with Reinforcement Learning**|M Deng et.al.|[2205.12548](https://arxiv.org/pdf/2205.12548.pdf)|EMNLP'22|[KOR](./TLDR/RLPROMPT-Optimizing-Discrete-Text-Prompts-with-Reinforcement-Learning.md)|
|**02-13**|**Iter-RetGen: Enhancing Retrieval augmented Large Language Models with Iterative Retrieval**|Z Shao et.al.|[2305.15294](https://arxiv.org/pdf/2305.15294.pdf)|ACL'23|[KOR](./TLDR/Iter-RetGen-Enhancing-Retrieval-augmented-Large-Language-Models-with-Iterative-Retrieval.md)|
|**02-12**|**InstructGPT: Training language models to follow instructions with human feedback**|L Ouyang et.al.|[2203.02155](https://arxiv.org/pdf/2203.02155.pdf)|NeurIPS'22, OpenAI|[KOR](./TLDR/InstructGPT-Training-language-models-to-follow-instructions-with-human-feedback.md)|
|**02-11**|**LIMA: Less Is More for Alignment**|C Zhou et.al.|[2305.11206](https://arxiv.org/pdf/2305.11206.pdf)|preprint'23, MetaAI|[KOR](./TLDR/LIMA-Less-Is-More-for-Alignment.md)|
|**02-10**|**MCSE: Multimodal Contrastive Learning of Sentence Embeddings**|M Zhang et.al.|[2204.10931](https://arxiv.org/pdf/2204.10931.pdf)|NAACL'22|[KOR](./TLDR/MCSE-Multimodal-Contrastive-Learning-of-Sentence-Embeddings.md)|
|**02-09**|**LLaMA: Open and Efficient Foundation Language Models**|H Touvron et.al.|[2302.13971](https://arxiv.org/pdf/2302.13971.pdf)|preprint'23, MetaAI|[KOR](./TLDR/LLaMA-Open-and-Efficient-Foundation-Language-Models.md)|
|**02-08**|**INSTRUCTION TUNING WITH GPT-4**|B Peng et.al.|[2304.03277](https://arxiv.org/pdf/2304.03277.pdf)|preprint'23|[KOR](./TLDR/INSTRUCTION-TUNING-WITH-GPT-4.md)|
|**02-07**|**Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering**|S Siriwardhana et.al.|[2210.02627](https://arxiv.org/pdf/2210.02627.pdf)|TACL'23|[KOR](./TLDR/Improving-the-Domain-Adaptation-of-Retrieval-Augmented-Generation-(RAG)-Models-for-Open-Domain-Question-Answering.md)|
|**02-06**|**Mistral 7B**|AQ Jiang et.al.|[2310.06825](https://arxiv.org/pdf/2310.06825.pdf)|preprint'23|[KOR](./TLDR/Mistral-7B.md)|
|**02-05**|**The Internal State of an LLM Knows When its Lying**|A Azaria et.al.|[2304.13734](https://arxiv.org/pdf/2304.13734.pdf)|EMNLP'23|[KOR](./TLDR/The-Internal-State-of-an-LLM-Knows-When-its-Lying.md)|
|**02-04**|**DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction**|M Pourreza et.al.|[2304.11015](https://arxiv.org/pdf/2304.11015.pdf)|NeurIPS'23|[KOR](./TLDR/DIN-SQL-Decomposed-In-Context-Learning-of-Text-to-SQL-with-Self-Correction.md)|
|**02-03**|**Revisiting the Gold Standard: Summarization Evaluation with Robust Human Evaluation**|Y Liu et.al.|[2212.07981](https://arxiv.org/pdf/2212.07981.pdf)|ACL'23|[KOR](./TLDR/Revisiting-the-Gold-Standard-Summarization-Evaluation-with-Robust-Human-Evaluation.md)|
|**02-02**|**PEER: A Collaborative Language Model**|T Schick et.al.|[2208.11663](https://arxiv.org/pdf/2208.11663.pdf)|ICLR'23|[KOR](./TLDR/PEER-A-Collaborative-Language-Model.md)|
|**02-01**|**DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models**|YS Chuang et.al.|[2309.03883](https://arxiv.org/pdf/2309.03883.pdf)|ICLR'24|[KOR](./TLDR/DoLa-Decoding-by-Contrasting-Layers-Improves-Factuality-in-Large-Language-Models.md)|
|**01-31**|**Can Large Language Models Be an Alternative to Human Evaluation?**|CH Chiang et.al.|[2305.01937](https://arxiv.org/pdf/2305.01937.pdf)|ACL'23, LLM, evaluation|[KOR](./TLDR/Can-Large-Language-Models-Be-an-Alternative-to-Human-Evaluation.md)|
|**01-30**|**When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories**|A Mallen et.al.|[2212.10511](https://arxiv.org/pdf/2212.10511.pdf)|ACL'23, LLM, QA|[KOR](./TLDR/When-not-to-trust-language-models-Investigating-effectiveness-and-limitations-of-parametric-and-non-parametric-memories.md)|
|**01-29**|**Align before Fuse: Vision and Language Representation Learning with Momentum Distillation**|SY Gadre et.al.|[2107.07651](https://arxiv.org/pdf/2107.07651.pdf)|NeurIPS'21, Distillation, Multi-modal|[KOR](./TLDR/Align-before-Fuse-Vision-and-Language-Representation-Learning-with-Momentum-Distillation.md)|
|**01-28**|**Making Large Language Models Better Reasoners with Step-Aware Verifier**|Y Li et.al.|[2206.02336](https://arxiv.org/pdf/2206.02336.pdf)|ACL'23, Reasoning|[KOR](./TLDR/Making-Large-Language-Models-Better-Reasoners-with-Step-Aware-Verifier.md)|
|**01-27**|**LONGEVAL: Guidelines for Human Evaluation of Faithfulness in Long-form Summarization**|K Krishna et.al.|[2301.13298](https://arxiv.org/pdf/2301.13298.pdf)|EACL'23, Summarization|[KOR](./TLDR/LONGEVAL-Guidelines-for-Human-Evaluation-of-Faithfulness-in-Long-form-Summarization.md)|
|**01-26**|**SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization**|H Kim et.al.|[2212.10465](https://arxiv.org/pdf/2212.10465.pdf)|EMNLP'23, Distillation|[KOR](./TLDR/SODA-Million-scale-Dialogue-Distillation-with-Social-Commonsense-Contextualization.md)|
|**01-25**|**OpenAssistant Conversations: Democratizing Large Language Model Alignment**|A Köpf et.al.|[2304.07327](https://arxiv.org/pdf/2304.07327.pdf)|NeurIPS'23, LLM|[KOR](./TLDR/OpenAssistant-Conversations-Democratizing-Large-Language-Model-Alignment.md)|
|**01-24**|**Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection**|Y Bai et.al.|[2306.04637](https://arxiv.org/pdf/2306.04637.pdf)|NeurIPS'23, In-Context Learning|[KOR](./TLDR/Transformers-as-Statisticians-Provable-In-Context-Learning-with-In-Context-Algorithm-Selection.md)|
|**01-23**|**DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings**|YS Chuang et.al.|[2204.10298](https://arxiv.org/pdf/2204.10298.pdf)|NAACL'22, Contrasive Learning|[KOR](./TLDR/DiffCSE-Difference-based-Contrastive-Learning-for-Sentence-Embeddings.md)|
|**01-22**|**ProQA: Structural Prompt-based Pre-training for Unified Question Answering**|W Zhong et.al.|[2205.04040](https://arxiv.org/pdf/2205.04040.pdf)|NAACL'22, QA, prompt|[KOR](./TLDR/ProQA-Structural-Prompt-based-Pre-training-for-Unified-Question-Answering.md)|
|**01-21**|**DataComp: In search of the next generation of multimodal datasets**|SY Gadre et.al.|[2304.14108](https://arxiv.org/pdf/2304.14108.pdf)|ACL'23, benchmark|[KOR](./TLDR/DataComp-In-search-of-the-next-generation-of-multimodal-datasets.md)|
|**01-20**|**LeanDojo: Theorem Proving with Retrieval-Augmented Language Models**|K Yang et.al.|[2306.15626](https://arxiv.org/pdf/2306.15626.pdf)|NeurIPS'23, Retrieval-Augmented|[KOR](./TLDR/LeanDojo-Theorem-Proving-with-Retrieval-Augmented-Language-Models.md)|
|**01-19**|**NewsEdits: A Dataset of News Article Revision Histories and a Novel Document-Level Reasoning Challenge**|A Spangher et.al.|[2206.07106](https://arxiv.org/pdf/2206.07106.pdf)|NAACL'22, Dataset, Reasoning|[KOR](./TLDR/NewsEdits-A-Dataset-of-News-Article-Revision-Histories-and-a-Novel-Document-Level-Reasoning-Challenge.md)|
|**01-18**|**What the DAAM: Interpreting Stable Diffusion Using Cross Attention**|R Tang et.al.|[2210.04885](https://arxiv.org/pdf/2210.04885.pdf)|ACL'23, multi-modal|[KOR](./TLDR/What-the-DAAM-Interpreting-Stable-Diffusion-Using-Cross-Attention.md)|
|**01-17**|**Do Androids Laugh at Electric Sheep? Humor Understanding Benchmarks from The New Yorker Caption Contest**|J.Hessel et.al.|[2209.06293](https://arxiv.org/pdf/2209.06293.pdf)|ACL'23, benchmark|[KOR](./TLDR/Do-Androids-Laugh-at-Electric-Sheep-Humor-Understanding-Benchmarks-from-The-New-Yorker-Caption-Contest.md)|
|**01-16**|**Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions**|M.Parmar et.al.|[2205.00415](https://arxiv.org/pdf/2205.00415.pdf)|EACL'23, annotation|[KOR](./TLDR/Don't-Blame-the-Annotator-Bias-Already-Starts-in-the-Annotation-Instructions.md)|
|**01-15**|**DECODINGTRUST: A Comprehensive Assessment of Trustworthiness in GPT Models**|Yuqi Nie et.al.|[2306.11698](https://arxiv.org/pdf/2306.11698.pdf)|NeurIPS'23, evaluation|[KOR](./TLDR/DECODINGTRUST-A-Comprehensive-Assessment-of-Trustworthiness-in-GPT-Models.md)|
|**01-14**|**Do Prompt-Based Models Really Understand the Meaning of Their Prompts?**|Albert Webson et.al.|[2109.01247](https://arxiv.org/pdf/2109.01247.pdf)|NAACL'22, prompt|[KOR](./TLDR/Do-Prompt-Based-Models-Really-Understand-the-Meaning-of-Their-Prompts.md)|
|**01-13**|**Template-free Prompt Tuning for Few-shot NER**|Ruotian Ma et.al.|[2109.13532](https://arxiv.org/pdf/2109.13532.pdf)|NAACL'22, prompt|[KOR](./TLDR/Template-free-Prompt-Tuning-for-Few-shot-NER.md)|
|**01-12**|**Probing via Prompting and Pruning**|Jiaoda Li et.al.|[2207.01736](https://arxiv.org/pdf/2207.01736.pdf)|NAACL'22, prompt|[KOR](./TLDR/Probing-via-Prompting-and-Pruning.md)|
|**01-11**|**Are Emergent Abilities of Large Language Models a Mirage?**|R.Schaeffer et.al.|[2304.15004](https://arxiv.org/pdf/2304.15004.pdf)|NeurIPS'23, LLM|[KOR](./TLDR/Are-Emergent-Abilities-of-Large-Language-Models-a-Mirage.md)|
|**01-10**|**Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters**|B.Wang et.al.|[2212.10001](https://arxiv.org/pdf/2212.10001.pdf)|ACL'23, prompt|[KOR](./TLDR/Towards-Understanding-Chain-of-Thought-Prompting-An-Empirical-Study-of-What-Matters.md)|
|**01-09**|**A TIME SERIES IS WORTH 64 WORDS: LONG-TERM FORECASTING WITH TRANSFORMERS**|Yuqi Nie et.al.|[2211.14730](https://arxiv.org/pdf/2211.14730.pdf)|ICLR'23, time-series|[KOR](./TLDR/A-TIME-SERIES-IS-WORTH-64-WORDS-LONG-TERM-FORECASTING-WITH-TRANSFORMERS.md)|
|**01-08**|**Do PLMs Know and Understand Ontological Knowledge?**|Weiqi Wu et.al.|[2309.05936](https://arxiv.org/pdf/2309.05936.pdf)|ACL'23, PLM|[KOR](./TLDR/Do-PLMs-Know-and-Understand-Ontological-Knowledge.md)|
|**01-07**|**QLoRA: Efficient Finetuning of Quantized LLMs**|Tim Dettmers et.al.|[2305.14314](https://arxiv.org/pdf/2305.14314.pdf)|NeurIPS'23, fine-tuning|[KOR](./TLDR/QLoRA-Efficient-Finetuning-of-Quantized-LLMs.md)| 
|**01-06**|**Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents**|Weiwei Sun et.al.|[2105.09680](https://arxiv.org/pdf/2105.09680.pdf)|EMNLP'23, LLM|[KOR](./TLDR/Is-ChatGPT-Good-at-Search-Investigating-Large-Language-Models-as-Re-Ranking-Agents.md)|
|**01-05**|**Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models**|Myra Cheng et.al.|[2305.18189](https://arxiv.org/pdf/2305.18189.pdf)|ACL'23, prompt|[KOR](./TLDR/Marked-Personas-Using-Natural-Language-Prompts-to-Measure-Stereotypes-in-Language-Models.md)|
|**01-04**|**From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models**|Shangbin Feng et.al.|[2305.08283](https://arxiv.org/pdf/2305.08283.pdf)|ACL'23, AI ethics|[KOR](./TLDR/From-Pretraining-Data-to-Language-Models-to-Downstream-Tasks-Tracking-the-Trails-of-Political-Biases-Leading-to-Unfair-NLP-Models.md)|
|**01-03**|**Mamba: Linear-Time Sequence Modeling with Selective State Spaces**|Albert Gu et.al.|[2312.00752](https://arxiv.org/ftp/arxiv/papers/2312/2312.00752.pdf)|ICLR'24, LLM|[KOR](./TLDR/Mamba-Linear-Time-Sequence-Modeling-with-Selective-State-Spaces.md)|
|**01-02**|**FRUIT: Faithfully Reflecting Updated Information in Text**|Robert L. Logan IV et.al.|[2112.08634](https://arxiv.org/pdf/2112.08634.pdf)|NAACL'22, Information, dataset|[KOR](./TLDR/FRUIT-Faithfully-Reflecting-Updated-Information-in-Text.md)|
|**01-01**|**Scaling Data-Constrained Language Models**|Niklas Muennighoff et.al.|[2305.16264](https://arxiv.org/pdf/2305.16264.pdf)|NeurIPS'23, LLM|[KOR](./TLDR/Scaling-Data-Constrained-Language-Models.md)|

